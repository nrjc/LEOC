from typing import List, Tuple
import gin
import numpy as np
from matplotlib import pyplot as plt
import tensorflow as tf
from tf_agents.environments.py_environment import PyEnvironment
from tf_agents.trajectories.trajectory import Trajectory

plt.style.use('seaborn-darkgrid')


class Plotter(object):
    """
    This class plots different graphs for a single epoch from
    a list of trajectories generated by eval
    """

    def __init__(self):
        self.observations = []
        self.rewards = []
        self.actions = []
        self.ratio = []
        self.timesteps = 0
        plt.style.use('seaborn-darkgrid')

    def __call__(self, trajectories: List[Trajectory], **kwargs) -> None:
        raise NotImplementedError

    def traj2obs(self) -> np.ndarray:
        """
        Input:
            trajectories: trajectories from eval
        Output:
            np.ndarray of state observations
        """
        observations = [i.numpy()[0] for i in self.observations]
        observations = np.array(observations[:self.timesteps])
        return observations

    def traj2theta(self, obs_idx: int, acos: bool) -> np.ndarray:
        """
        Input:
            trajectories: trajectories from eval
            obs_idx: index of the observation corresponding to cosine
        Output:
            np.ndarray of states
        """
        observations = self.traj2obs()
        cos_theta = observations[:self.timesteps, obs_idx]
        theta = tf.math.acos(cos_theta) if acos else cos_theta
        return theta

    def traj2info(self) -> np.ndarray:
        """
        Input:
            trajectories: trajectories from eval
        Output:
            np.ndarray of info/controller ratios
        """
        try:
            ratios = [i.numpy()[0] for i in self.ratio]
        except AttributeError:
            ratios = self.ratio
        ratios = np.array(ratios[:self.timesteps])
        return ratios


@gin.configurable
class StatePlotter(Plotter):
    def __init__(self, env: PyEnvironment):
        super(StatePlotter, self).__init__()
        # Depending on the env, cos(theta) or state of interest is located at different obs_idx
        if env.unwrapped.spec.id == 'Pendulum-v7' or env.unwrapped.spec.id == 'Pendulum-v8':
            self.acos = True
            self.obs_idx = 0
        elif env.unwrapped.spec.id == 'Cartpole-v7' or env.unwrapped.spec.id == 'Cartpole-v8':
            self.acos = True
            self.obs_idx = 2
        elif env.unwrapped.spec.id == 'Mountaincar-v7' or env.unwrapped.spec.id == 'Mountaincar-v8':
            self.acos = False
            self.obs_idx = 0
        else:
            raise Exception('--- Error: Wrong env in StatePlotter ---')

    def __call__(self, trajectories: List[Trajectory], num_episodes=1) -> None:
        self.trajectories = trajectories
        self.observations = [x.observation for x in trajectories]
        self.rewards = [x.reward for x in trajectories]
        self.actions = [x.action for x in trajectories]
        self.ratio = [x.policy_info for x in trajectories]
        self.timesteps = int(len(self.observations) / num_episodes)

        thetas = self.traj2theta(self.obs_idx, self.acos)
        ratios = self.traj2info()

        fig, ax1 = plt.subplots(figsize=(6, 4))

        # Plot theta
        ln1 = ax1.plot(np.arange(self.timesteps), thetas, color='royalblue', label='\u03B8')
        ax1.set_xlabel('Timesteps')
        ax1.legend()
        ax1.set_title(f'\u03B8 and Controller Ratio')

        # Plot linear ratio
        ax2 = ax1.twinx()
        ln2 = ax2.plot(np.arange(self.timesteps), ratios, color='darkorange', label='Controller Ratio')

        # Set legend and format
        lns = ln1 + ln2
        labs = [l.get_label() for l in lns]
        ax1.legend(lns, labs, loc=7)
        ax2.grid(False)
        fig.show()


@gin.configurable
class ControlMetricsPlotter(Plotter):
    def __init__(self, env: PyEnvironment):
        super(ControlMetricsPlotter, self).__init__(env)

    def __call__(self, trajectories: List[Trajectory]) -> None:
        pass

    def traj2metrics(self, target: List[float], stability_bound: float) -> Tuple[float, int, int]:
        """
        Input:
            trajectories: trajectories from eval
        Output:
            np.ndarray of the control theory metrics
        """
        theta = self.traj2theta()
        peak_overshot = max(abs(theta)) - target
        rising_time = theta.index(max(theta))

        theta_reverse = theta[::-1]
        upper_stability_bound, lower_stability_bound = target + stability_bound, target - stability_bound
        settling_time = np.argmax(lower_stability_bound < theta_reverse < upper_stability_bound)
        settling_time = len(theta_reverse) - settling_time

        return (peak_overshot, rising_time, settling_time)


class LearningCurvePlotter(object):
    """
    This class plots learning curves for the entire training session from
    a list of np.arrays
    """

    def __init__(self, rewards: List[np.ndarray]):
        self.rewards = rewards

    def __call__(self) -> None:
        pass
